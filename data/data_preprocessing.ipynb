{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Data Preprocessing (used from https://github.com/MLforHealth/MIMIC_Extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from mmd_grud_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x143d4ae1570>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FILEPATH     = 'all_hourly_data.h5'\n",
    "RAW_DATA_FILEPATH = 'all_hourly_data.h5'\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics = statics[statics.age<= 100]\n",
    "data_full_lvl2 = data_full_lvl2.loc[statics.index.get_level_values(0).unique()]\n",
    "data_full_raw = data_full_raw.loc[statics.index.get_level_values(0).unique()]\n",
    "\n",
    "statics.drop(27994,axis = 0,inplace = True)\n",
    "data_full_lvl2.drop(27994,axis = 0,inplace = True)\n",
    "data_full_raw.drop(27994,axis = 0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lloyd\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexing.py:1884: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, val, pi)\n"
     ]
    }
   ],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "\n",
    "lvl2, raw = [df[\n",
    "    (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] for df in (data_full_lvl2, data_full_raw)]\n",
    "\n",
    "#raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, raw, Ys)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "\n",
    "raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lloyd\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py:5042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test = [\n",
    "    simple_imputer(df) for df in (raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test)\n",
    "]\n",
    "raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test\n",
    "    )\n",
    "]\n",
    "\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test, raw_train, raw_dev, raw_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add los>7 and los>3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "[(Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (Ys,)\n",
    "]\n",
    "\n",
    "train_subject_id = lvl2_train.index.get_level_values(0)\n",
    "dev_subject_id = lvl2_dev.index.get_level_values(0)\n",
    "test_subject_id = lvl2_test.index.get_level_values(0)\n",
    "\n",
    "intervention = pd.read_hdf('all_hourly_data.h5', 'interventions')\n",
    "patients = pd.read_hdf('all_hourly_data.h5', 'patients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize patient age and categorise ethnicities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_max_age = patients.age.max()\n",
    "patients['age'] = patients.age/patients_max_age\n",
    "\n",
    "def categorize_ethnicity(ethnicity):\n",
    "    if 'ASIAN' in ethnicity:\n",
    "        ethnicity = 'ASIAN'\n",
    "    elif 'WHITE' in ethnicity:\n",
    "        ethnicity = 'WHITE'\n",
    "    elif 'HISPANIC' in ethnicity:\n",
    "        ethnicity = 'HISPANIC/LATINO'\n",
    "    elif 'BLACK' in ethnicity:\n",
    "        ethnicity = 'BLACK'\n",
    "#    elif 'AMERICAN INDIAN' in ethnicity:\n",
    "#        ethnicity = 'AMERICAN INDIAN'\n",
    "    else: \n",
    "        ethnicity = 'OTHER'\n",
    "    return ethnicity\n",
    "\n",
    "patients['ethnicity'] = patients.ethnicity.apply(lambda x : categorize_ethnicity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervention_train = intervention.loc[train_subject_id.unique()]\n",
    "patients_train = patients.loc[train_subject_id.unique()]\n",
    "\n",
    "intervention_test = intervention.loc[test_subject_id.unique()]\n",
    "patients_test = patients.loc[test_subject_id.unique()]\n",
    "\n",
    "intervention_dev = intervention.loc[dev_subject_id.unique()]\n",
    "patients_dev = patients.loc[dev_subject_id.unique()]\n",
    "\n",
    "lvl2_train.to_pickle('vital_train.pkl')\n",
    "lvl2_dev.to_pickle('vital_dev.pkl')\n",
    "lvl2_test.to_pickle('vital_test.pkl')\n",
    "\n",
    "intervention_train.to_pickle('intervention_train.pkl')\n",
    "intervention_test.to_pickle('intervention_test.pkl')\n",
    "intervention_dev.to_pickle('intervention_dev.pkl')\n",
    "\n",
    "patients_train = patients_train[['gender','ethnicity','age','insurance']]\n",
    "patients_test = patients_test[['gender','ethnicity','age','insurance']]\n",
    "patients_dev = patients_dev[['gender','ethnicity','age','insurance']]\n",
    "\n",
    "patients_train.to_pickle('patients_train.pkl')\n",
    "patients_test.to_pickle('patients_test.pkl')\n",
    "patients_dev.to_pickle('patients_dev.pkl')\n",
    "\n",
    "Ys_train.to_pickle('y_train.pkl')\n",
    "Ys_test.to_pickle('y_test.pkl')\n",
    "Ys_dev.to_pickle('y_dev.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file = 'mimic3Processed.h5'\n",
    "\n",
    "patients_train.to_hdf(hdf_file,format = \"table\",key = \"patients_train\")\n",
    "patients_dev.to_hdf(hdf_file,format = \"table\",key = \"patients_dev\")\n",
    "patients_test.to_hdf(hdf_file,format = \"table\",key = \"patients_test\")\n",
    "\n",
    "vitals_train.to_hdf(hdf_file,format = \"fixed\",key = \"vitals_train\")\n",
    "vitals_dev.to_hdf(hdf_file,format = \"fixed\",key = \"vitals_dev\")\n",
    "vitals_test.to_hdf(hdf_file,format = \"fixed\",key = \"vitals_test\")\n",
    "\n",
    "intervention_train.to_hdf(hdf_file,format = \"table\",key = \"intervention_train\")\n",
    "intervention_dev.to_hdf(hdf_file,format = \"table\",key = \"intervention_dev\")\n",
    "intervention_test.to_hdf(hdf_file,format = \"table\",key = \"intervention_test\")\n",
    "\n",
    "y_train.to_hdf(hdf_file,format = \"table\",key = \"y_train\")\n",
    "y_dev.to_hdf(hdf_file,format = \"table\",key = \"y_dev\")\n",
    "y_test.to_hdf(hdf_file,format = \"table\",key = \"y_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
